{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef ask_ai():\\n    index = GPTSimpleVectorIndex.load_from_disk(\\'index.json\\')\\n    while True: \\n        query = input(\"What do you want to ask? \")\\n        response = index.query(query)\\n        display(Markdown(f\"Response: <b>{response.response}</b>\"))\\n        '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper, ServiceContext\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    # set number of output tokens\n",
    "    num_outputs = 2000\n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600 \n",
    "\n",
    "    # define prompt helper\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.5, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
    " \n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    \n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "    index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "'''\n",
    "def ask_ai():\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    while True: \n",
    "        query = input(\"What do you want to ask? \")\n",
    "        response = index.query(query)\n",
    "        display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x20e0fa0d870>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_index(\"./data/dummy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waqar.saddique\\AppData\\Local\\Temp\\ipykernel_13712\\2356652510.py:9: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
      "C:\\Users\\Waqar.saddique\\AppData\\Local\\Temp\\ipykernel_13712\\2356652510.py:9: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
      "C:\\Users\\Waqar.saddique\\AppData\\Local\\Temp\\ipykernel_13712\\2356652510.py:9: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 512, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1070, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1341, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 798, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 512, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1070, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1341, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 106, in get_embedding\n",
      "    return openai.Embedding.create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\embedding.py\", line 33, in create\n",
      "    response = super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\routes.py\", line 439, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1384, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1089, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\utils.py\", line 700, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Waqar.saddique\\AppData\\Local\\Temp\\ipykernel_13712\\2356652510.py\", line 4, in llama_index\n",
      "    response = index.query(query)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\base.py\", line 244, in query\n",
      "    return query_runner.query(query_str)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py\", line 342, in query\n",
      "    return query_combiner.run(query_bundle, level)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\query_combiner\\base.py\", line 66, in run\n",
      "    return self._query_runner.query_transformed(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py\", line 202, in query_transformed\n",
      "    return query_obj.query(query_bundle)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\token_counter\\token_counter.py\", line 78, in wrapped_llm_predict\n",
      "    f_return_val = f(_self, *args, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 396, in query\n",
      "    return self._query(query_bundle)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 382, in _query\n",
      "    nodes = self.retrieve(query_bundle)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 249, in retrieve\n",
      "    nodes = self._retrieve(query_bundle, similarity_tracker=similarity_tracker)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base_query.py\", line 53, in _retrieve\n",
      "    self._service_context.embed_model.get_agg_embedding_from_queries(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 79, in get_agg_embedding_from_queries\n",
      "    query_embeddings = [self.get_query_embedding(query) for query in queries]\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 79, in <listcomp>\n",
      "    query_embeddings = [self.get_query_embedding(query) for query in queries]\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 68, in get_query_embedding\n",
      "    query_embedding = self._get_query_embedding(query)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 223, in _get_query_embedding\n",
      "    return get_embedding(query, engine=engine)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x20e0fb81630 state=finished raised APIConnectionError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 512, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1070, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1341, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 798, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 512, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1070, in _create\n",
      "    self.do_handshake()\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1341, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 106, in get_embedding\n",
      "    return openai.Embedding.create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\embedding.py\", line 33, in create\n",
      "    response = super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\routes.py\", line 439, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1384, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1089, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\utils.py\", line 700, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Waqar.saddique\\AppData\\Local\\Temp\\ipykernel_13712\\2356652510.py\", line 4, in llama_index\n",
      "    response = index.query(query)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\base.py\", line 244, in query\n",
      "    return query_runner.query(query_str)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py\", line 342, in query\n",
      "    return query_combiner.run(query_bundle, level)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\query_combiner\\base.py\", line 66, in run\n",
      "    return self._query_runner.query_transformed(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\query_runner.py\", line 202, in query_transformed\n",
      "    return query_obj.query(query_bundle)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\token_counter\\token_counter.py\", line 78, in wrapped_llm_predict\n",
      "    f_return_val = f(_self, *args, **kwargs)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 396, in query\n",
      "    return self._query(query_bundle)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 382, in _query\n",
      "    nodes = self.retrieve(query_bundle)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 249, in retrieve\n",
      "    nodes = self._retrieve(query_bundle, similarity_tracker=similarity_tracker)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base_query.py\", line 53, in _retrieve\n",
      "    self._service_context.embed_model.get_agg_embedding_from_queries(\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 79, in get_agg_embedding_from_queries\n",
      "    query_embeddings = [self.get_query_embedding(query) for query in queries]\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 79, in <listcomp>\n",
      "    query_embeddings = [self.get_query_embedding(query) for query in queries]\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 68, in get_query_embedding\n",
      "    query_embedding = self._get_query_embedding(query)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 223, in _get_query_embedding\n",
      "    return get_embedding(query, engine=engine)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\Waqar.saddique\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x20e0fb6e620 state=finished raised APIConnectionError>]\n"
     ]
    }
   ],
   "source": [
    "# creating fuctions for gradio\n",
    "def llama_index(query):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    response = index.query(query)\n",
    "    return response.response\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=llama_index,\n",
    "    inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"LLAMA Index\",\n",
    "    description=\"Ask a question and get an answer from the LLAMA Index.\",\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
